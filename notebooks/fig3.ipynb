{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e21764",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "sys.path.insert(0, \"./../\")\n",
    "from FileManager import FileManager\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54a81ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getenv(\"DATASETPATH\"), \"qwem\")\n",
    "data_fm = FileManager(data_dir)\n",
    "\n",
    "analogy_dict = data_fm.load(\"analogies.pickle\")\n",
    "if analogy_dict is None:\n",
    "    raise FileNotFoundError(\"Analogy file not found.\")\n",
    "\n",
    "data_fm.set_filepath(\"enwiki500\")\n",
    "word_counts = data_fm.load(\"word_counts.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fe6703",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwem_dir = os.path.join(os.getenv(\"EXPTPATH\"), \"qwem\", \"qwem-small\")\n",
    "sgns_dir = os.path.join(os.getenv(\"EXPTPATH\"), \"qwem\", \"sgns-small\")\n",
    "qweml_dir = os.path.join(os.getenv(\"EXPTPATH\"), \"qwem\", \"qwem-large\")\n",
    "sgnsl_dir = os.path.join(os.getenv(\"EXPTPATH\"), \"qwem\", \"sgns-large\")\n",
    "\n",
    "fm = FileManager(qwem_dir)\n",
    "with open(fm.get_filename(\"hypers.json\")) as f:\n",
    "    H = json.load(f)\n",
    "\n",
    "VOCAB_SZ = H[\"vocab_sz\"]\n",
    "EMBEDDIM = H[\"embeddim\"]\n",
    "vocab = utils.Vocabulary(word_counts[:VOCAB_SZ])\n",
    "unigram = vocab.counts / vocab.counts.sum()\n",
    "analogy_dataset = utils.AnalogyDataset(analogy_dict, vocab)\n",
    "\n",
    "benchmark_fm = FileManager('./benchmarks')\n",
    "models = benchmark_fm.load(f\"models_d{EMBEDDIM}_V{VOCAB_SZ}.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c80cb1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing M*... done.\n",
      "starting.. done.\n",
      "starting.. done.\n",
      "starting.. done.\n"
     ]
    }
   ],
   "source": [
    "if models is None:\n",
    "    def get_W(expt_dir):\n",
    "        expt_fm = FileManager(expt_dir)\n",
    "        expt_fm.set_filepath(\"models\")\n",
    "        W = expt_fm.load(\"W_final.npy\")\n",
    "        V, S, _ = np.linalg.svd(W, full_matrices=False)\n",
    "        W = V @ np.diag(S)\n",
    "        return W\n",
    "    \n",
    "    def get_W_from_M(M, d):\n",
    "        print(\"starting.. \", end='')\n",
    "        M = torch.tensor(M, dtype=torch.float64).cuda()\n",
    "        eigvals, eigvecs = torch.linalg.eigh(M)\n",
    "        eigvals, eigvecs = eigvals.flip(dims=(0,)), eigvecs.flip(dims=(1,))\n",
    "        eigvals, eigvecs = eigvals.cpu().numpy(), eigvecs.cpu().numpy()\n",
    "        W = eigvecs[:, :d] @ np.diag(np.sqrt(eigvals[:d]))\n",
    "        print(\"done.\")\n",
    "        return W\n",
    "\n",
    "    W_QWEM = get_W(qwem_dir)\n",
    "    W_SGNS = get_W(sgns_dir)\n",
    "    \n",
    "    print(f\"Computing M*... \", end=\"\")\n",
    "    corpus_stats = data_fm.load(\"corpus_stats.pickle\")\n",
    "    cL = corpus_stats[\"context_len\"]\n",
    "    Cij, Crwij = corpus_stats[\"counts\"], corpus_stats[\"counts_reweight\"]\n",
    "    numcounts = Cij[:VOCAB_SZ, :VOCAB_SZ].sum()\n",
    "    Pij = Crwij[:VOCAB_SZ, :VOCAB_SZ] / (numcounts * (cL + 1)/2)\n",
    "    PiPj = np.outer(unigram, unigram)\n",
    "    Mstar = 2*(Pij - PiPj)/(Pij + PiPj)\n",
    "    PMI = np.log((Pij / PiPj) + 1e-25)\n",
    "    print(\"done.\")\n",
    "\n",
    "    W_Mstar = get_W_from_M(Mstar, EMBEDDIM)\n",
    "    W_PMI = get_W_from_M(PMI, EMBEDDIM)\n",
    "    W_PPMI = get_W_from_M(np.maximum(0, PMI), EMBEDDIM)\n",
    "    \n",
    "    models = {\n",
    "        \"SGNS\": W_SGNS,\n",
    "        \"QWEM\": W_QWEM,\n",
    "        \"Mstar\": W_Mstar,\n",
    "        \"PPMI\": W_PPMI,\n",
    "        \"PMI\": W_PMI,\n",
    "    }\n",
    "    benchmark_fm.save(models, f\"models_d{EMBEDDIM}_V{VOCAB_SZ}.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9114be2",
   "metadata": {},
   "source": [
    "## Eval benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b13ee9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1588\n",
      "249\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "def read_similarity_data(file_path, vocab):\n",
    "    similarity_data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) == 3:\n",
    "                word1, word2, similarity = parts[0], parts[1], float(parts[2])\n",
    "                if word1 in vocab.word2token and word2 in vocab.word2token:\n",
    "                    similarity_data.append([vocab.word2token[word1],\n",
    "                                            vocab.word2token[word2],\n",
    "                                            similarity])\n",
    "    return similarity_data\n",
    "\n",
    "\n",
    "def evaluate_similarity(W, similarity_data):\n",
    "    norms = np.linalg.norm(W, axis=1, keepdims=True)\n",
    "    embeds = W / (norms + 1e-10)\n",
    "    \n",
    "    predicted_sims, human_sims = [], []\n",
    "    \n",
    "    for tok1, tok2, similarity in similarity_data:\n",
    "        predicted_sims.append(np.dot(embeds[tok1], embeds[tok2]).item())\n",
    "        human_sims.append(similarity)\n",
    "    \n",
    "    if len(predicted_sims) == 0:\n",
    "        raise ValueError(\"No valid word pairs found in embeddings.\")\n",
    "    \n",
    "    return spearmanr(predicted_sims, human_sims).correlation\n",
    "\n",
    "dataset_dir = os.getenv(\"DATASETPATH\")\n",
    "mendir = os.path.join(dataset_dir, \"qwem/benchmarks/MEN.txt\")\n",
    "ws353dir = os.path.join(dataset_dir, \"qwem/benchmarks/ws353.txt\")\n",
    "men_dataset = read_similarity_data(mendir, vocab)\n",
    "ws353_dataset = read_similarity_data(ws353dir, vocab)\n",
    "print(len(men_dataset))\n",
    "print(len(ws353_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42bf616f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGNS\n",
      "Analogy acc: 67.9\n",
      "MEN score: 0.743\n",
      "ws353 score: 0.6962\n",
      "\n",
      "QWEM\n",
      "Analogy acc: 65.0\n",
      "MEN score: 0.753\n",
      "ws353 score: 0.6814\n",
      "\n",
      "Mstar\n",
      "Analogy acc: 66.5\n",
      "MEN score: 0.756\n",
      "ws353 score: 0.6829\n",
      "\n",
      "PPMI\n",
      "Analogy acc: 50.7\n",
      "MEN score: 0.744\n",
      "ws353 score: 0.6900\n",
      "\n",
      "PMI\n",
      "Analogy acc: 8.6\n",
      "MEN score: 0.444\n",
      "ws353 score: 0.2034\n",
      "\n"
     ]
    }
   ],
   "source": [
    "benchmarks = [\"Google analogies\", \"MEN\", \"ws353\"]\n",
    "results = np.empty((len(models.items()), len(benchmarks)))\n",
    "for i, (k, W) in enumerate(models.items()):\n",
    "    print(k)\n",
    "    acc = analogy_dataset.eval_accuracy(W)\n",
    "    results[i, 0] = acc\n",
    "    print(f\"Analogy acc: {100*acc:.1f}\")\n",
    "    \n",
    "    rho = evaluate_similarity(W, men_dataset).mean().item()\n",
    "    results[i, 1] = rho\n",
    "    print(f\"MEN score: {rho:.3f}\")\n",
    "    \n",
    "    rho = evaluate_similarity(W, ws353_dataset).mean().item()\n",
    "    results[i, 2] = rho\n",
    "    print(f\"ws353 score: {rho:.4f}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "179c61a8",
   "metadata": {},
   "source": [
    "## Eigenfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba634f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA dir 1\n",
      "-0.025 lemmon kitt socorro spacewatch fefefe id sort km median right peak households expatriate mount establishments hispanic footballers survey bgcolor census\n",
      "-0.507 eric cooper jones sam dennis oliver tom robinson roberts thompson harris jack miller lewis scott michael taylor moore wilson barry\n",
      "\n",
      "PCA dir 2\n",
      "0.468 furthermore requires can specific useful require therefore particular processes example typically such component whereas types specifically components possible additionally appropriate\n",
      "-0.598 jones dennis eric robinson scott taylor oliver michael roberts david miller smith harris lewis thompson cooper moore russell mitchell wilson\n",
      "\n",
      "PCA dir 3\n",
      "0.322 like can uses simple makes soft typical baby typically shape combination featuring eyes usually using surface happy dark similar charlie\n",
      "-0.410 government establishment governments foreign authorities leaders declared civil officials behalf political independence citizens sought federal union commission relations organisation administration\n",
      "\n",
      "PCA dir 9\n",
      "0.303 equipment operating enterprise provided company services customers operate designed companies purchase service corporation mobile commercial ltd installed retail maintenance private\n",
      "-0.468 team win playoff tigers season consecutive playoffs winning giants finished league scoring tied wins champions seasons played victory losing lions\n",
      "\n",
      "PCA dir 10\n",
      "0.294 interpretation simple frame clearly object element simply reference view mounted context william describes elements principle indeed definition read sense theory\n",
      "-0.334 food affected habitat populations plants diseases growth forests agricultural fish agriculture increase disease areas sugar plant grown growing increased risk\n",
      "\n",
      "PCA dir 11\n",
      "0.393 deployed force combat forces patrol naval command squadron attack allied army enemy submarine armed troops artillery war invasion missile missions\n",
      "-0.293 tax property if any pay shall must otherwise not accept maria de apply buy money limit granted n debt without\n",
      "\n",
      "PCA dir 12\n",
      "0.303 opposition opposed independence backing guitar government drums bass bill produced producer vocals parties featured dave coalition democratic ruling regime party\n",
      "-0.320 she her decides goes reveals seeing find tells asks wants herself everyone sees help learn tries begins meets hospital at\n",
      "\n",
      "PCA dir 13\n",
      "0.273 glass painted made skin wooden pieces clothing twice legs competition competitive food finishing competitions winning first occasions placed finished trophy\n",
      "-0.402 southwest northeast northwest north southeast boundary valley highway route southern east river south west lake along lies crossing hills creek\n",
      "\n",
      "PCA dir 14\n",
      "0.351 piano vocal solo orchestra music instrumental recordings songs choir tracks recording op violin symphony concert performances organ album lyrics performed\n",
      "-0.298 dragon clan appears voiced spider uses giant han dynasty princess hero legend evil uncle software elder son warriors king tribe\n",
      "\n",
      "PCA dir 15\n",
      "0.322 alleged wall arrest shaped accused inside investigation criminal roof arrested walls wooden floor glass crimes interior victim denied window doors\n",
      "-0.263 thus england great meant price share enjoyed liverpool came biggest earl expected britain time anglo ever demand therefore success lord\n",
      "\n",
      "PCA dir 100\n",
      "0.179 newspaper newspapers advertising senior knight freedom promoted flying posted magazines order grand post spread examples colonial reporting merit honours reporter\n",
      "-0.193 org figure standing riding with http green date external www relationship links despite parent sources link child archive whom entry\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NORMALIZE = True\n",
    "# W = models[\"QWEM\"]\n",
    "W = models[\"PPMI\"]\n",
    "# W = models[\"SGNS\"]\n",
    "\n",
    "V, S, Ut = np.linalg.svd(W, full_matrices=False)\n",
    "assert np.allclose(np.abs(Ut), np.eye(EMBEDDIM))\n",
    "norms = np.linalg.norm(W, axis=1, keepdims=True) if NORMALIZE else 1\n",
    "embeds = W / norms\n",
    "\n",
    "dd = [1, 2, 3, 9, 10, 11, 12, 13, 14, 15, 100]\n",
    "for d in dd:\n",
    "    vec = embeds[:, d-1]\n",
    "    idxs = np.argsort(vec[:4000])[::-1]\n",
    "    vec_sort = vec[idxs]\n",
    "    print(f\"PCA dir {d}\")\n",
    "    print(f'{(vec_sort[:10]).mean():.3f} {vocab.to_words(idxs[:20])}')\n",
    "    print(f'{(vec_sort[-10:]).mean():.3f} {vocab.to_words(idxs[-20:][::-1])}')\n",
    "    print()   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-torch (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
